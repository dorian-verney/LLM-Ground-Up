{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d591829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaa61af",
   "metadata": {},
   "source": [
    "## Preparing the supervised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3541fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "    \n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55fddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      "{'input': 'He go to the park every day.',\n",
      " 'instruction': 'Edit the following sentence for grammar.',\n",
      " 'output': 'He goes to the park every day.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\")\n",
    "pprint.pprint(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61c33218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      "{'input': '',\n",
      " 'instruction': 'Convert 45 kilometers to meters.',\n",
      " 'output': '45 kilometers is 45000 meters.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\")\n",
    "pprint.pprint(data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc6cd63",
   "metadata": {},
   "source": [
    "$\\rightarrow$ **input can be optional**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430f9844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "    return instruction_text + input_text\n",
    "\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea23f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7ef35e",
   "metadata": {},
   "source": [
    "*Partioning the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bff632cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8315ac01",
   "metadata": {},
   "source": [
    "## Organizing data into training batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1684c",
   "metadata": {},
   "source": [
    "Let's create our custom collate function used for batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69031863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "964c310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598ebfc2",
   "metadata": {},
   "source": [
    "This custom collate function pads the training examples in each batch to the same length while allowing different batches to have different lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "232dc4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100,\n",
    "                        allowed_max_length=None, device=\"cpu\"):\n",
    "\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        # Replaces all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "            \n",
    "        # Optionally truncates to the maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff179b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4fac3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "# print(inputs)\n",
    "# print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab31fba",
   "metadata": {},
   "source": [
    "**We take advantage of this ignore_index to ignore the additional end-of-text (padding) tokens\n",
    "that we used to pad the training examples to have the same length in each batch.**\n",
    "\n",
    "**However, we want to keep one 50256 (end-of-text) token ID in the targets because it\n",
    "helps the LLM to learn to generate end-of-text tokens, which we can use as an indica-\n",
    "tor that a response is complete.**\n",
    "\n",
    "**By masking out the LLMâ€™s target token IDs corresponding to the instruction, the cross\n",
    "entropy loss is only computed for the generated response target IDs. Thus, the model\n",
    "is trained to focus on generating accurate responses rather than memorizing instruc-\n",
    "tions, which can help reduce overfitting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcac1b3e",
   "metadata": {},
   "source": [
    "## Creating data loaders for an instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f846344",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# used to pre-fill (bind) some arguments of a function, creating a new function with fewer parameters.\n",
    "\n",
    "from functools import partial\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26f83dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e6f6278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 56]) torch.Size([8, 56])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974d183",
   "metadata": {},
   "source": [
    "## Loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56a76bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorian/AI/LLMFromScratch/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../../OpenAI-GPT/355M/checkpoint\n",
      "File already exists and is up-to-date: ../../OpenAI-GPT/355M/encoder.json\n",
      "File already exists and is up-to-date: ../../OpenAI-GPT/355M/hparams.json\n",
      "File already exists and is up-to-date: ../../OpenAI-GPT/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: ../../OpenAI-GPT/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: ../../OpenAI-GPT/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: ../../OpenAI-GPT/355M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.gpt_download import download_and_load_gpt2\n",
    "from utils.utils import GPTModel\n",
    "from utils.utils import load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257, # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0, # Dropout rate\n",
    "    \"qkv_bias\": True # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"../../OpenAI-GPT/\"\n",
    ")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37d02368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af1eea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import generate, text_to_token_ids, token_ids_to_text\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f09a74c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c4c34",
   "metadata": {},
   "source": [
    "## Fine-tuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "319ba88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8875033855438232\n",
      "Validation loss: 3.7619349479675295\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import calc_loss_loader, train_model_simple, evaluate_model\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_loss, val_loss = evaluate_model(\n",
    "    model, train_loader, val_loader, device, eval_iter=5\n",
    ")\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "870450d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_input(val_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc749ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Ep 1 (Step 000000): Train loss 2.544, Val loss 2.615\n",
      "Ep 1 (Step 000005): Train loss 1.045, Val loss 1.117\n",
      "Ep 1 (Step 000010): Train loss 0.942, Val loss 0.977\n",
      "Ep 1 (Step 000015): Train loss 0.887, Val loss 0.933\n",
      "Ep 1 (Step 000020): Train loss 0.800, Val loss 0.902\n",
      "Ep 1 (Step 000025): Train loss 0.788, Val loss 0.867\n",
      "Ep 1 (Step 000030): Train loss 0.683, Val loss 0.830\n",
      "Ep 1 (Step 000035): Train loss 0.654, Val loss 0.802\n",
      "Ep 1 (Step 000040): Train loss 0.654, Val loss 0.794\n",
      "Ep 1 (Step 000045): Train loss 0.727, Val loss 0.775\n",
      "Ep 1 (Step 000050): Train loss 0.682, Val loss 0.762\n",
      "Ep 1 (Step 000055): Train loss 0.570, Val loss 0.753\n",
      "Ep 1 (Step 000060): Train loss 0.663, Val loss 0.737\n",
      "Ep 1 (Step 000065): Train loss 0.624, Val loss 0.728\n",
      "Ep 1 (Step 000070): Train loss 0.568, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.653, Val loss 0.731\n",
      "Ep 1 (Step 000080): Train loss 0.528, Val loss 0.724\n",
      "Ep 1 (Step 000085): Train loss 0.503, Val loss 0.714\n",
      "Ep 1 (Step 000090): Train loss 0.498, Val loss 0.698\n",
      "Ep 1 (Step 000095): Train loss 0.457, Val loss 0.697\n",
      "Ep 1 (Step 000100): Train loss 0.490, Val loss 0.671\n",
      "Ep 1 (Step 000105): Train loss 0.459, Val loss 0.662\n",
      "Ep 1 (Step 000110): Train loss 0.484, Val loss 0.667\n",
      "Ep 1 (Step 000115): Train loss 0.474, Val loss 0.659\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The active sentence is 'The chef cooks the meal every day.'<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the following sentence\n",
      "Ep 2 (Step 000120): Train loss 0.426, Val loss 0.655\n",
      "Ep 2 (Step 000125): Train loss 0.406, Val loss 0.657\n",
      "Ep 2 (Step 000130): Train loss 0.478, Val loss 0.666\n",
      "Ep 2 (Step 000135): Train loss 0.399, Val loss 0.666\n",
      "Ep 2 (Step 000140): Train loss 0.416, Val loss 0.656\n",
      "Ep 2 (Step 000145): Train loss 0.400, Val loss 0.657\n",
      "Ep 2 (Step 000150): Train loss 0.441, Val loss 0.655\n",
      "Ep 2 (Step 000155): Train loss 0.445, Val loss 0.662\n",
      "Ep 2 (Step 000160): Train loss 0.403, Val loss 0.675\n",
      "Ep 2 (Step 000165): Train loss 0.394, Val loss 0.677\n",
      "Ep 2 (Step 000170): Train loss 0.431, Val loss 0.663\n",
      "Ep 2 (Step 000175): Train loss 0.346, Val loss 0.657\n",
      "Ep 2 (Step 000180): Train loss 0.359, Val loss 0.661\n",
      "Ep 2 (Step 000185): Train loss 0.346, Val loss 0.668\n",
      "Ep 2 (Step 000190): Train loss 0.322, Val loss 0.669\n",
      "Ep 2 (Step 000195): Train loss 0.358, Val loss 0.675\n",
      "Ep 2 (Step 000200): Train loss 0.325, Val loss 0.669\n",
      "Ep 2 (Step 000205): Train loss 0.366, Val loss 0.654\n",
      "Ep 2 (Step 000210): Train loss 0.326, Val loss 0.653\n",
      "Ep 2 (Step 000215): Train loss 0.316, Val loss 0.648\n",
      "Ep 2 (Step 000220): Train loss 0.329, Val loss 0.641\n",
      "Ep 2 (Step 000225): Train loss 0.350, Val loss 0.647\n",
      "Ep 2 (Step 000230): Train loss 0.323, Val loss 0.641\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the chemical formula for sodium hydroxide\n",
      "Training completed in 7.45 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(42)\n",
    "print(\"Device:\", device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=0.00005, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 2\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97f34d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "    epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00c8edab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4bd791",
   "metadata": {},
   "source": [
    "## Extracting and saving responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc70b045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> Thunderstorms typically form in the atmosphere over the surface of the Earth. They typically are composed of electrically charged particles, typically nitrogen, oxygen, or carbon dioxide.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a63f691",
   "metadata": {},
   "source": [
    "*Generating test set responses for future evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c0d4ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [02:08<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "408abe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'The car is very fast.',\n",
      " 'instruction': 'Rewrite the sentence using a simile.',\n",
      " 'model_response': 'The car is as fast as a cheetah.',\n",
      " 'output': 'The car is as fast as lightning.'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8099ec",
   "metadata": {},
   "source": [
    "*saving model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73b21bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc7632b",
   "metadata": {},
   "source": [
    "## Evaluating the fine-tuned LLM - LLM as a judge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cbc0ad",
   "metadata": {},
   "source": [
    "### 1. Ollama running locally (llama.cpp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d632d154",
   "metadata": {},
   "source": [
    "### 2. VIA OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91fdeac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc848d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_chatgpt(prompt, client, model=\"gpt-4o\"):\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=model,\n",
    "#         messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "#         temperature=0.0,\n",
    "#         seed=123,\n",
    "#     )\n",
    "#     return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# prompt = \"Respond with 'hello world' if you got this message.\"\n",
    "# run_chatgpt(prompt, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed014011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMFromScratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

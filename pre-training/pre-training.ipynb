{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54c0b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import GPTModel, text_to_token_ids, token_ids_to_text\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef2a207",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af57997e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a64b6313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8496,  8705, 11185,  5899,  5059],\n",
      "        [32273,  7986,   416,  7506,   290]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Where engineering meets pure driving\" # -> emotion\n",
    "txt2 = \"Performance driven by passion and\" # -> precision\n",
    "\n",
    "inputs = torch.tensor([[ 8496,  8705, 11185,  5899,  5059],\n",
    "                        [32273,  7986,   416,  7506,   290]])\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0304552f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8705, 11185,  5899,  5059,  9942],\n",
      "        [ 7986,   416,  7506,   290, 15440]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \" engineering meets pure driving emotion\" # !! space at the beginning\n",
    "txt2 = \" driven by passion and precision\"        # !! space at the beginning\n",
    "\n",
    "target = torch.tensor([[8705, 11185,  5899,  5059,  9942], \n",
    "                        [7986,   416,  7506,   290, 15440]])\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c84a3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' driven by passion and precision'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(target[1], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc5af469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08b57204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[32740],\n",
      "         [29437],\n",
      "         [41346],\n",
      "         [24075],\n",
      "         [25568]],\n",
      "\n",
      "        [[41078],\n",
      "         [ 7752],\n",
      "         [11682],\n",
      "         [24075],\n",
      "         [25053]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53d478dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  engineering meets pure driving emotion\n",
      "Outputs batch 1:  advertise Hip Tayyip Wisdom evid\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(target[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497c807d",
   "metadata": {},
   "source": [
    "Initial softmax probability scores corresponding to the target tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da57b550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8705, 11185,  5899,  5059,  9942])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b665fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2, 3, 4], target[text_idx]] # element-wise pairing\n",
    "target_probas_2 = probas[text_idx+1, [0, 1, 2, 3, 4], target[text_idx+1]] # element-wise pairing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86208cb3",
   "metadata": {},
   "source": [
    "The five target token ID probabilities for each batch are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9920251e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([1.1580e-05, 1.6736e-05, 2.8208e-05, 2.4584e-05, 4.6892e-06])\n",
      "Text 2: tensor([1.0677e-05, 4.0786e-05, 8.7535e-06, 1.8054e-05, 8.2586e-06])\n"
     ]
    }
   ],
   "source": [
    "print(\"Text 1:\", target_probas_1)\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b2058",
   "metadata": {},
   "source": [
    "The goal of training an LLM is to maximize the likelihood of the correct token, which involves increasing its probability relative to other tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb8521e",
   "metadata": {},
   "source": [
    "Next, we will calculate the loss for the probability scores of the two example batches\n",
    "`target_probas_1` and `target_probas_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f712c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-11.3663, -10.9979, -10.4759, -10.6134, -12.2702, -11.4474, -10.1072,\n",
      "        -11.6461, -10.9221, -11.7043])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f489ad",
   "metadata": {},
   "source": [
    "**We want these elements to be all 0  (perfect proba because 0 = log(1))** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08fd31c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.1551)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = torch.mean(log_probas) * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1468946c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 5, 50257])\n",
      "Targets shape: torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1a0154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([10, 50257])\n",
      "Flattened targets: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1) # flatten over batch dimensions\n",
    "targets_flat = target.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "595fd84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: tensor([ 8705, 11185,  5899,  5059,  9942,  7986,   416,  7506,   290, 15440])\n",
      "Logits: tensor([[ 0.4087,  0.1997, -0.5199,  ..., -0.3985,  0.3230,  0.7249],\n",
      "        [-0.8661,  0.4375, -0.6254,  ..., -0.1029, -0.2341, -0.5498],\n",
      "        [ 1.0092,  0.1547, -0.4411,  ..., -1.4171,  0.4751, -0.5188],\n",
      "        ...,\n",
      "        [ 0.3038, -0.2348, -1.1240,  ..., -0.0361,  0.3286, -0.8969],\n",
      "        [-0.5163, -0.0297, -0.1895,  ...,  0.0890, -0.1572,  0.6877],\n",
      "        [ 1.0698,  0.0430,  0.6543,  ..., -0.2441,  0.5043,  0.5913]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Targets:\", targets_flat)\n",
    "print(\"Logits:\", logits_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15c80a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.1551)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47456762",
   "metadata": {},
   "source": [
    "#### Computing train / val losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be925d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../porsche_text/origin.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "031f780c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 17938\n",
      "Tokens: 4075\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d47c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38a4568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import create_dataloader_v1\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54c22890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([1, 256]) torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c175cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4f6c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d1e93f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Training loss: 10.987626211983818\n",
      "Validation loss: 10.982877731323242\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e380c2",
   "metadata": {},
   "source": [
    "## Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbe46951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import generate_text_simple\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d0936c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5c208dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                        optimizer, device, num_epochs,\n",
    "                        eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "    \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                ) \n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1708f8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.821, Val loss 10.288\n",
      "Ep 1 (Step 000005): Train loss 8.139, Val loss 8.909\n",
      "The company has been highly, the the the the the the the the the the the, the the the the the the the the the the the the the the the the the the the the the the, the the the the the, the the the the the the the the\n",
      "Ep 2 (Step 000010): Train loss 6.790, Val loss 7.981\n",
      "The company has been highly, the, the, the, the, the, the, the the, the, the the, the, the the, the, the, the the the the, the the, the the the, the the, the the the the the\n",
      "Ep 3 (Step 000015): Train loss 6.064, Val loss 7.804\n",
      "Ep 3 (Step 000020): Train loss 5.529, Val loss 7.908\n",
      "The company has been highly.                                                 \n",
      "Ep 4 (Step 000025): Train loss 5.407, Val loss 7.929\n",
      "The company has been highly                                                  \n",
      "Ep 5 (Step 000030): Train loss 5.049, Val loss 7.836\n",
      "The company has been highly.                                                 \n",
      "Ep 6 (Step 000035): Train loss 4.652, Val loss 7.854\n",
      "Ep 6 (Step 000040): Train loss 4.165, Val loss 8.028\n",
      "The company has been highly, the 911, which is the 356, which is Volkswagen AG, which had a new, which had a new, and 914 and 914-cyl and the company, the 356, the 356, who was responsible for the company, the\n",
      "Ep 7 (Step 000045): Train loss 3.928, Val loss 7.834\n",
      "The company has been highly.       In, and the company, and in the company, the Volkswagen AG, and the company, and in the Volkswagen AG, and the 356 to be. The Porsche, and was responsible for the company. \n",
      "Ep 8 (Step 000050): Train loss 3.104, Val loss 7.836\n",
      "Ep 8 (Step 000055): Train loss 2.688, Val loss 7.833\n",
      "The company has been highly. In August Volkswagen Beetle, and Volkswagen AG was the Volkswagen Beetle was in the Volkswagen AG, the Volkswagen Beetle, the Volkswagen AG, and 914-WÃ¼rttemberg-cylinder-, a new mixed-cylinder-cyl\n",
      "Ep 9 (Step 000060): Train loss 2.145, Val loss 7.839\n",
      "The company has been highly. In August 2022, and has become Porsche's production of the 356 was replaced in the company.        In August] and the company, to be listed on the company, and the company.   \n",
      "Ep 10 (Step 000065): Train loss 1.733, Val loss 7.870\n",
      "The company has been highly. In August 2022, the Volkswagen, Porsche's production, which is renowned for exclusive sunglasses, the Volkswagen Beetle, and many other luxury articles. A. Porsche's son, the Porsche SE, the company. Porsche's son and the Volkswagen-\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"The company has been highly\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6edc81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "    epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8dbbeb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3847eb76",
   "metadata": {},
   "source": [
    "## Decoding strategies to control randomness\n",
    "\n",
    "- temperature scaling\n",
    "- top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55f0d210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46555284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Porsche North America confirmed.\n",
      "In August 2022, the Volkswagen, Porsche's production, which is renowned for exclusive sunglasses, the Volkswagen Beetle, the\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Porsche North America confirmed\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c987ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e48cfc5",
   "metadata": {},
   "source": [
    "Assuming we have these logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17375876",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55acb97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n",
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])\n",
    "\n",
    "# replaced by \n",
    "\n",
    "torch.manual_seed(42)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed666c",
   "metadata": {},
   "source": [
    "**The multinomial function samples the next token proportional to its probability score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb905b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "577 x forward\n",
      "5 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "345 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(42)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca804d",
   "metadata": {},
   "source": [
    "*temperature*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc5dcf",
   "metadata": {},
   "source": [
    "*Temperatures greater than 1 result in more uniformly distributed token probabilities,\n",
    "and temperatures smaller than 1 will result in more confident (sharper or more peaky)\n",
    "distributions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "daa9dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc3784a",
   "metadata": {},
   "source": [
    "*top k*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e13f494e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6dc776d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New logits: tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(\"New logits:\", new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "adf22645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1454218c",
   "metadata": {},
   "source": [
    "Modifying the text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aeae3e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "    \n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc6341aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Porsche North America confirmed with designed by a $80â has PiÃ«ch, to produce the\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Porsche North America confirmed\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7ece6",
   "metadata": {},
   "source": [
    "## Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caff554",
   "metadata": {},
   "source": [
    "*Saving*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a9d5094",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c60b1f2",
   "metadata": {},
   "source": [
    "*Loading*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "413c7f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c101e",
   "metadata": {},
   "source": [
    "## Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7adfe776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x35b1e76a0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db1e615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorian/AI/LLMFromScratch/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "checkpoint: 100%|ââââââââââ| 77.0/77.0 [00:00<00:00, 141kiB/s]\n",
      "encoder.json: 100%|ââââââââââ| 1.04M/1.04M [00:00<00:00, 1.20MiB/s]\n",
      "hparams.json: 100%|ââââââââââ| 90.0/90.0 [00:00<00:00, 89.3kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|ââââââââââ| 498M/498M [08:24<00:00, 987kiB/s]   \n",
      "model.ckpt.index: 100%|ââââââââââ| 5.21k/5.21k [00:00<00:00, 4.59MiB/s]\n",
      "model.ckpt.meta: 100%|ââââââââââ| 471k/471k [00:00<00:00, 759kiB/s] \n",
      "vocab.bpe: 100%|ââââââââââ| 456k/456k [00:00<00:00, 719kiB/s] \n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(  \n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0016f1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c757591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    # \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    # \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    # \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9627b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95fd3ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5be6728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f750f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "        \n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "     \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3d0be20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8c85378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Porsche North America confirmed the model of the Porsche 911 Carrera S did not have anything in fact to do with the 2016 MRE's car number\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Porsche North America confirmed\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116bf13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMFromScratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
